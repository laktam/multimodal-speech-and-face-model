{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 625,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os import listdir\n",
    "from PIL import Image\n",
    "from numpy import asarray\n",
    "from numpy import expand_dims\n",
    "from matplotlib import pyplot\n",
    "from keras.models import load_model\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Concatenate, Dropout, BatchNormalization\n",
    "import pickle\n",
    "import cv2\n",
    "import librosa\n",
    "from keras_facenet import FaceNet\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define face model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 626,
   "metadata": {},
   "outputs": [],
   "source": [
    "HaarCascade = cv2.CascadeClassifier(cv2.samples.findFile(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml'))\n",
    "face_model = FaceNet()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define speech model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 100\n",
    "speech_model = load_model('speech_embedding_model.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\laktam\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# final_model = Sequential()\n",
    "\n",
    "# # ce model prend comme entree la concatenation des embeddings\n",
    "# final_model.add(Dense(64, activation='relu', input_shape=(640,))) # face net produice embedding of size 512 + 128 (speech embedding)\n",
    "# final_model.add(Dropout(0.8))\n",
    "# final_model.add(Dense(32, activation='relu'))\n",
    "# final_model.add(Dropout(0.7))\n",
    "# final_model.add(Dense(5, activation='softmax'))\n",
    "\n",
    "# final_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# Input layer\n",
    "model.add(Dense(256, input_dim=640, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.7))\n",
    "\n",
    "# Hidden layers\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.7))\n",
    "\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.7))\n",
    "\n",
    "# Output layer\n",
    "# Adjust the units and activation function according to your prediction task\n",
    "model.add(Dense(5, activation='softmax'))  # For classification\n",
    "\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# final_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating pre-processing methods for image and audio data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cette method fait l'extraction de visage dans l'image (HaarCascade)\n",
    "def get_face_from_image(path):\n",
    "    gbr1 = cv2.imread(path)\n",
    "    \n",
    "    faces = HaarCascade.detectMultiScale(gbr1,1.1,4)\n",
    "    \n",
    "    if len(faces)>0:\n",
    "        x1, y1, width, height = faces[0]         \n",
    "    else:\n",
    "        x1, y1, width, height = 1, 1, 10, 10\n",
    "        \n",
    "    x1, y1 = abs(x1), abs(y1)\n",
    "    x2, y2 = x1 + width, y1 + height\n",
    "    \n",
    "    gbr = cv2.cvtColor(gbr1, cv2.COLOR_BGR2RGB)\n",
    "    gbr = Image.fromarray(gbr)                  # conversion from OpenCV to PIL\n",
    "    gbr_array = asarray(gbr)\n",
    "    \n",
    "    face = gbr_array[y1:y2, x1:x2]                        \n",
    "    \n",
    "    face = Image.fromarray(face)                       \n",
    "    face = face.resize((160,160))\n",
    "    face = asarray(face)\n",
    "    \n",
    "    # face = face.astype('float32')\n",
    "    # mean, std = face.mean(), face.std()\n",
    "    # face = (face - mean) / std\n",
    "    \n",
    "    face = expand_dims(face, axis=0)\n",
    "    return face"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extraction des features du speech (mfcc)\n",
    "def extract_features(file_path):\n",
    "    y, sr = librosa.load(file_path, sr=None)\n",
    "    mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)# 13 = refers to the number of extracted features\n",
    "    return mfcc.T  # Transpose to have time steps first"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepar trainning data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop over speech data set\n",
    "# for each file in speech dataset\n",
    "# get the name\n",
    "# get the corespending image\n",
    "# pass the image and the audio to the two models (prepar audio (mfcc, padding))\n",
    "# create two lists (data, labels)\n",
    "# append the concatenated version to data and the name to labels\n",
    "from sklearn.preprocessing import StandardScaler,MinMaxScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# passer sur la dataset et generer les embeddings et les labels\n",
    "def extract_embeddings_and_labels(speech_dataset, image_dataset):\n",
    "    i = 0\n",
    "    embeddings = []\n",
    "    labels = []\n",
    "\n",
    "    for file_name in os.listdir(speech_dataset):\n",
    "        if file_name.endswith('.wav'):\n",
    "            print(i)\n",
    "            i = i+1\n",
    "            file_path = os.path.join(speech_dataset, file_name)\n",
    "            features = extract_features(file_path)\n",
    "            #padding\n",
    "            padded_features = pad_sequences([features], maxlen=max_length, padding='post', dtype='float32')\n",
    "            speech_embedding = speech_model.predict(padded_features)\n",
    "            # print(\"speech embedding \" , speech_embedding)\n",
    "            ## preparing face\n",
    "            # getting image name from speech filename\n",
    "            name = file_name.split('_')[0]\n",
    "            image_path = os.path.join(image_dataset, name + \".jpg\")\n",
    "            # print(\"image path \", image_path)\n",
    "            face = get_face_from_image(image_path)\n",
    "            face_embedding = face_model.embeddings(face)\n",
    "            # print(\"embedding of face \" ,name ,  face_embedding)\n",
    "            # concatenation\n",
    "\n",
    "            # Normalize embeddings\n",
    "            # face_embedding = scaler.fit_transform(face_embedding)\n",
    "            # speech_embedding = scaler.fit_transform(speech_embedding)\n",
    "\n",
    "\n",
    "            concatenated_embedding = np.concatenate((face_embedding[0], speech_embedding[0]))#, axis=1 axis was 0 !!!!!!!!!!!\n",
    "            embeddings.append(concatenated_embedding)\n",
    "            labels.append(name)\n",
    "            # because model take a numpy array\n",
    "            embeddings_array = np.array(embeddings)\n",
    "\n",
    "    return embeddings_array, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step\n",
      "1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step\n",
      "2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step\n",
      "3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step\n",
      "4\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step\n",
      "5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step\n",
      "6\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step\n",
      "7\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[624], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m embeddings, labels \u001b[38;5;241m=\u001b[39m \u001b[43mextract_embeddings_and_labels\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mspeech_dataset\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mimage_dataset\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[623], line 34\u001b[0m, in \u001b[0;36mextract_embeddings_and_labels\u001b[1;34m(speech_dataset, image_dataset)\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;66;03m# print(\"image path \", image_path)\u001b[39;00m\n\u001b[0;32m     33\u001b[0m face \u001b[38;5;241m=\u001b[39m get_face_from_image(image_path)\n\u001b[1;32m---> 34\u001b[0m face_embedding \u001b[38;5;241m=\u001b[39m \u001b[43mface_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43mface\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;66;03m# print(\"embedding of face \" ,name ,  face_embedding)\u001b[39;00m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;66;03m# concatenation\u001b[39;00m\n\u001b[0;32m     37\u001b[0m \n\u001b[0;32m     38\u001b[0m \u001b[38;5;66;03m# Normalize embeddings\u001b[39;00m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;66;03m# face_embedding = scaler.fit_transform(face_embedding)\u001b[39;00m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;66;03m# speech_embedding = scaler.fit_transform(speech_embedding)\u001b[39;00m\n\u001b[0;32m     43\u001b[0m concatenated_embedding \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate((face_embedding[\u001b[38;5;241m0\u001b[39m], speech_embedding[\u001b[38;5;241m0\u001b[39m]))\u001b[38;5;66;03m#, axis=1 axis was 0 !!!!!!!!!!!\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\laktam\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras_facenet\\__init__.py:113\u001b[0m, in \u001b[0;36mFaceNet.embeddings\u001b[1;34m(self, images)\u001b[0m\n\u001b[0;32m    111\u001b[0m images \u001b[38;5;241m=\u001b[39m [cv2\u001b[38;5;241m.\u001b[39mresize(image, (s, s)) \u001b[38;5;28;01mfor\u001b[39;00m image \u001b[38;5;129;01min\u001b[39;00m images]\n\u001b[0;32m    112\u001b[0m X \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mfloat32([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_normalize(image) \u001b[38;5;28;01mfor\u001b[39;00m image \u001b[38;5;129;01min\u001b[39;00m images])\n\u001b[1;32m--> 113\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m embeddings\n",
      "File \u001b[1;32mc:\\Users\\laktam\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\laktam\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:504\u001b[0m, in \u001b[0;36mTensorFlowTrainer.predict\u001b[1;34m(self, x, batch_size, verbose, steps, callbacks)\u001b[0m\n\u001b[0;32m    502\u001b[0m callbacks\u001b[38;5;241m.\u001b[39mon_predict_batch_begin(step)\n\u001b[0;32m    503\u001b[0m data \u001b[38;5;241m=\u001b[39m get_data(iterator)\n\u001b[1;32m--> 504\u001b[0m batch_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    505\u001b[0m outputs \u001b[38;5;241m=\u001b[39m append_to_outputs(batch_outputs, outputs)\n\u001b[0;32m    506\u001b[0m callbacks\u001b[38;5;241m.\u001b[39mon_predict_batch_end(step, {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutputs\u001b[39m\u001b[38;5;124m\"\u001b[39m: batch_outputs})\n",
      "File \u001b[1;32mc:\\Users\\laktam\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\laktam\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\laktam\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[0;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[1;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[0;32m    880\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[0;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\laktam\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[1;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[0;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[1;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[0;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\laktam\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[0;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1324\u001b[0m     args,\n\u001b[0;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1326\u001b[0m     executing_eagerly)\n\u001b[0;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\laktam\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[1;32mc:\\Users\\laktam\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[0;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[0;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[0;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[0;32m    261\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\laktam\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\context.py:1500\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1498\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[0;32m   1499\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1500\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1501\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1502\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1503\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1504\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1505\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1506\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1507\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1508\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1509\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1510\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1514\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[0;32m   1515\u001b[0m   )\n",
      "File \u001b[1;32mc:\\Users\\laktam\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "embeddings, labels = extract_embeddings_and_labels(\"speech_dataset\", \"image_dataset\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i added normalization in the model\n",
    "\n",
    "# def normalize_embeddings(embeddings):\n",
    "#     # scaler = StandardScaler()\n",
    "#     # normalized_embeddings = scaler.fit_transform(embeddings)\n",
    "#     scaler = MinMaxScaler()\n",
    "#     normalized_embeddings = scaler.fit_transform(embeddings)\n",
    "#     return normalized_embeddings\n",
    "\n",
    "# # Sample embeddings before normalization for inspection\n",
    "# print(\"Sample Embeddings Before Normalization:\", embeddings[0][:20])\n",
    "\n",
    "# # Normalize embeddings\n",
    "# normalized_embeddings = normalize_embeddings(embeddings)\n",
    "\n",
    "# # Sample normalized embeddings for inspection\n",
    "# print(\"Sample Normalized Embeddings:\", normalized_embeddings[0][:20])\n",
    "# normalized_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # save embeddings and labels\n",
    "with open('embeddings.pkl', 'wb') as f:\n",
    "    pickle.dump(embeddings, f)\n",
    "\n",
    "with open('labels.pkl', 'wb') as f:\n",
    "    pickle.dump(labels, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # load embeddins and labels\n",
    "# with open('old_embeddings/embeddings.pkl', 'rb') as f:\n",
    "#     embeddings = pickle.load(f)\n",
    "\n",
    "# with open('old_embeddings/labels.pkl', 'rb') as f:\n",
    "#     labels = pickle.load(f)\n",
    "\n",
    "# normalize embeddings\n",
    "\n",
    "\n",
    "train, test, labels_train, labels_test = train_test_split(\n",
    "    embeddings, labels, test_size=0.3, random_state=12 , stratify=labels\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Encodding \n",
    "label_encoder = LabelEncoder()\n",
    "encoded_labels_train = label_encoder.fit_transform(labels_train)\n",
    "\n",
    "# encoded_labels_test = label_encoder.fit_transform(labels_test)\n",
    "encoded_labels_test = label_encoder.transform(labels_test)\n",
    "\n",
    "labels_tain_one_hot = to_categorical(encoded_labels_train)\n",
    "labels_test_one_hot = to_categorical(encoded_labels_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_array = np.array(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - accuracy: 0.3374 - loss: 2.4329 - val_accuracy: 0.9810 - val_loss: 0.7163\n",
      "Epoch 2/10\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7006 - loss: 0.8032 - val_accuracy: 0.9810 - val_loss: 0.3640\n",
      "Epoch 3/10\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8318 - loss: 0.4534 - val_accuracy: 0.9873 - val_loss: 0.1878\n",
      "Epoch 4/10\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8844 - loss: 0.3288 - val_accuracy: 0.9873 - val_loss: 0.0992\n",
      "Epoch 5/10\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9205 - loss: 0.2509 - val_accuracy: 0.9873 - val_loss: 0.0577\n",
      "Epoch 6/10\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9363 - loss: 0.2264 - val_accuracy: 0.9937 - val_loss: 0.0379\n",
      "Epoch 7/10\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9444 - loss: 0.1952 - val_accuracy: 0.9937 - val_loss: 0.0282\n",
      "Epoch 8/10\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9540 - loss: 0.1627 - val_accuracy: 0.9937 - val_loss: 0.0267\n",
      "Epoch 9/10\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9764 - loss: 0.1205 - val_accuracy: 0.9937 - val_loss: 0.0245\n",
      "Epoch 10/10\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9530 - loss: 0.1913 - val_accuracy: 0.9937 - val_loss: 0.0216\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train, labels_tain_one_hot, epochs=10, batch_size=32,validation_split=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9720 - loss: 0.9720\n",
      "Test Accuracy: 97.63%\n"
     ]
    }
   ],
   "source": [
    "# test_array = np.array(test)\n",
    "\n",
    "loss, accuracy = model.evaluate(test, labels_test_one_hot)\n",
    "print(f'Test Accuracy: {accuracy * 100:.2f}%')\n",
    "\n",
    "# normalisation + 0.5 0.5 dropout : Test Accuracy: 19.11%\n",
    "# without normalisation + 0.5 0.5 dropout : Test Accuracy: 99.78%\n",
    "# normalisation + no dropout : Test Accuracy: 19.11%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot\n",
    "pyplot.title('Learning Curves')\n",
    "pyplot.xlabel('Epochs')\n",
    "pyplot.ylabel('Cross Entropy')\n",
    "pyplot.plot(history.history['loss'], label='train')\n",
    "pyplot.plot(history.history['val_loss'], label='val')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_concatenated_embedding(image_path, voice_path):\n",
    "    features = extract_features(voice_path)\n",
    "    #padding\n",
    "    padded_features = pad_sequences([features], maxlen=max_length, padding='post', dtype='float32')\n",
    "    speech_embedding = speech_model.predict(padded_features)\n",
    "\n",
    "    face = get_face_from_image(image_path)\n",
    "    face_embedding = face_model.embeddings(face)\n",
    "    # concatenation\n",
    "    concatenated_embedding = np.concatenate((face_embedding[0], speech_embedding[0]))\n",
    "    # returing a numpy array with one element to pass it directly to model\n",
    "    return np.array([concatenated_embedding])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step\n",
      "gates\n",
      "99.94%\n",
      "0.01%\n",
      "0.01%\n",
      "0.03%\n",
      "0.01%\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "trump\n",
      "0.03%\n",
      "0.05%\n",
      "0.05%\n",
      "0.04%\n",
      "99.83%\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "sam\n",
      "0.04%\n",
      "0.08%\n",
      "0.06%\n",
      "99.80%\n",
      "0.02%\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "mark\n",
      "1.85%\n",
      "76.70%\n",
      "18.71%\n",
      "2.08%\n",
      "0.66%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 1.8483522, 76.6961   , 18.714695 ,  2.075911 ,  0.664943 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 594,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding = generate_concatenated_embedding('extra_test_files/gates.jpeg','speech_dataset/gates_0_03_1.wav')# 'extra_test_files/0_12_9.wav'\n",
    "predictions = model.predict(embedding)\n",
    "decoded_labels= label_encoder.inverse_transform(np.argmax(predictions, axis=1))\n",
    "print(decoded_labels[0])\n",
    "ps = predictions[0] * 100 \n",
    "for p in ps:\n",
    "    print(f'{p:.2f}%')\n",
    "ps\n",
    "\n",
    "##############\n",
    "\n",
    "\n",
    "embedding = generate_concatenated_embedding('extra_test_files/trump.jpeg','speech_dataset/trump_2_05_36.wav')\n",
    "predictions = model.predict(embedding)\n",
    "decoded_labels= label_encoder.inverse_transform(np.argmax(predictions, axis=1))\n",
    "print(decoded_labels[0])\n",
    "ps = predictions[0] * 100 \n",
    "for p in ps:\n",
    "    print(f'{p:.2f}%')\n",
    "ps\n",
    "##########################\n",
    "embedding = generate_concatenated_embedding('extra_test_files/sam2.jpg','D:/MQL/S2/ML/Projet Image, Audio/speech_recognition/test_data/sam_9_04_0.wav')\n",
    "predictions = model.predict(embedding)\n",
    "decoded_labels= label_encoder.inverse_transform(np.argmax(predictions, axis=1))\n",
    "print(decoded_labels[0])\n",
    "ps = predictions[0] * 100 \n",
    "for p in ps:\n",
    "    print(f'{p:.2f}%')\n",
    "ps\n",
    "###############\n",
    "\n",
    "# unknown\n",
    "embedding = generate_concatenated_embedding('extra_test_files/tim.jpeg','extra_test_files/0_12_9.wav')# \n",
    "predictions = model.predict(embedding)\n",
    "decoded_labels= label_encoder.inverse_transform(np.argmax(predictions, axis=1))\n",
    "print(decoded_labels[0])\n",
    "\n",
    "# predictions = final_model.predict(test_array)\n",
    "# # predictions = predictions * 100\n",
    "ps = predictions[0] * 100 \n",
    "for p in ps:\n",
    "    print(f'{p:.2f}%')\n",
    "ps\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_person(predictions, threshold=0.9, unknown_label=\"unknown\"):\n",
    "    max_prob = max(predictions[0])\n",
    "    # max_index = np.argmax(predictions)\n",
    "    decoded_labels= label_encoder.inverse_transform(np.argmax(predictions, axis=1))\n",
    "   \n",
    "    if max_prob >= threshold:\n",
    "        # Person identified with high confidence\n",
    "        return decoded_labels[0]\n",
    "    else:\n",
    "        # Confidence below threshold, person is unknown\n",
    "        return unknown_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "gates\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "trump\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "sam\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "unknown\n"
     ]
    }
   ],
   "source": [
    "embedding = generate_concatenated_embedding('extra_test_files/gates.jpeg','speech_dataset/gates_0_03_1.wav')# 'extra_test_files/0_12_9.wav'\n",
    "predictions = model.predict(embedding)\n",
    "print(identify_person(predictions))\n",
    "##############\n",
    "embedding = generate_concatenated_embedding('extra_test_files/trump.jpeg','speech_dataset/trump_2_05_36.wav')\n",
    "predictions = model.predict(embedding)\n",
    "print(identify_person(predictions))\n",
    "##########################\n",
    "embedding = generate_concatenated_embedding('extra_test_files/sam2.jpg','D:/MQL/S2/ML/Projet Image, Audio/speech_recognition/test_data/sam_9_04_0.wav')\n",
    "predictions = model.predict(embedding)\n",
    "print(identify_person(predictions))\n",
    "###############\n",
    "\n",
    "# unknown\n",
    "embedding = generate_concatenated_embedding('extra_test_files/tim.jpeg','extra_test_files/0_12_9.wav')# \n",
    "predictions = model.predict(embedding)\n",
    "print(identify_person(predictions))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
